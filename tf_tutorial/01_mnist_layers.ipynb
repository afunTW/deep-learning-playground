{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN\n",
    "\n",
    "上一個練習中我們的 input data 是攤平成一維向量，然後自己調用底層 function 做數值運算\n",
    "\n",
    "這邊帶入 CNN 概念，講 input data 視為二維圖片處理，並調用 high-level functino 做一連串處理\n",
    "\n",
    "- tf.layers\n",
    "- name_scope\n",
    "- batch normalization (BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-65538b30ce46>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "tensorflow version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('data/mnist', one_hot=True)\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "print(f\"tensorflow version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(bz=128, ckpt_savepath='outputs/01_mnist_CNN/mnist_layers.ckpt', display_steps=100, gpu='3', input_shape=[784], lr=0.0001, n_output=10, steps=500)\n"
     ]
    }
   ],
   "source": [
    "def argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # training parameter\n",
    "    parser.add_argument('--gpu', dest='gpu', required=True, \\\n",
    "                        help='require one GPU to execute')\n",
    "    parser.add_argument('--lr', dest='lr', \\\n",
    "                        default=0.1, type=float, \\\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--steps', dest='steps', \\\n",
    "                        default=500, type=int, \\\n",
    "                        help='number of update steps')\n",
    "    parser.add_argument('--bz', dest='bz', \\\n",
    "                        default=128, type=int, \\\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--display-steps', dest='display_steps', \\\n",
    "                        default=100, type=int, \\\n",
    "                        help='display steps')\n",
    "    \n",
    "    # network parameter\n",
    "    parser.add_argument('--input-shape', dest='input_shape', \\\n",
    "                        default=784, nargs='+', type=int)\n",
    "    parser.add_argument('--num-class', dest='n_output', \\\n",
    "                        default=10, type=int)\n",
    "    parser.add_argument('--ckpt-savepath', dest='ckpt_savepath', \\\n",
    "                        default='outputs/01_mnist_CNN/mnist_layers.ckpt')\n",
    "    return parser\n",
    "\n",
    "# setting args\n",
    "args = argparser().parse_args([\n",
    "    '--gpu', '3',\n",
    "    '--lr', '0.0001',\n",
    "    '--input-shape', '784'\n",
    "])\n",
    "print(args)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(features, n_class):\n",
    "    # input layer\n",
    "    input_layer = tf.reshape(features, [-1, 28, 28, 1], name='input')\n",
    "    \n",
    "    # conv1\n",
    "    conv1 = tf.layers.conv2d(input_layer, filters=32, kernel_size=5, padding='same', name='conv_1')\n",
    "    conv1 = tf.layers.batch_normalization(conv1, name='bn_1')\n",
    "    conv1 = tf.nn.relu(conv1, name='relu_1')\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    # conv2\n",
    "    conv2 = tf.layers.conv2d(pool1, filters=64, kernel_size=5, padding='same', name='conv_2')\n",
    "    conv2 = tf.layers.batch_normalization(conv2, name='bn_2')\n",
    "    conv2 = tf.nn.relu(conv2, name='relu_2')\n",
    "    \n",
    "    # dense layer\n",
    "    flat = tf.layers.flatten(conv2, name='flatten')\n",
    "    dense = tf.layers.dense(flat, 1024, activation=tf.nn.relu, name='dense')\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.5)\n",
    "    \n",
    "    # output layer (logits)\n",
    "    output_layer = tf.layers.dense(dropout, n_class, name='output')\n",
    "    return output_layer\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define placeholder\n",
    "x_train = tf.placeholder('float', [None, *args.input_shape])\n",
    "y_train = tf.placeholder('float', [None, args.n_output])\n",
    "\n",
    "# define model graph\n",
    "logits = build_model(x_train, args.n_output)\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "\n",
    "# compile model - define loss and optimizer\n",
    "op_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_train))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=args.lr)\n",
    "op_update = optimizer.minimize(op_loss)\n",
    "\n",
    "# evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_train, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step    1 - loss=2.1879, acc=0.477\n",
      "step  100 - loss=0.2835, acc=0.906\n",
      "step  200 - loss=0.3227, acc=0.914\n",
      "step  300 - loss=0.1495, acc=0.938\n",
      "step  400 - loss=0.0932, acc=0.984\n",
      "optimization finished\n",
      "Save model - outputs/01_mnist_CNN/mnist_layers.ckpt\n",
      "Trining time - 0:00:08.023127\n"
     ]
    }
   ],
   "source": [
    "# # check model graph\n",
    "# import tensorflow.contrib.slim as slim\n",
    "# model_vars = tf.trainable_variables()\n",
    "# slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "\n",
    "# training\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "start_time = datetime.now()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # iterate update\n",
    "    for step in range(1, args.steps):\n",
    "        batch_x, batch_y = mnist_data.train.next_batch(args.bz)\n",
    "        \n",
    "        # optimize (back propagation) and print message\n",
    "        sess.run(op_update, feed_dict={x_train: batch_x, y_train: batch_y})\n",
    "        if step == 1 or step % args.display_steps == 0:\n",
    "            loss, acc = sess.run([op_loss, accuracy], feed_dict={x_train: batch_x, y_train: batch_y})\n",
    "            print(f\"step {step:4d} - loss={loss:.4f}, acc={acc:.3f}\")\n",
    "    print('optimization finished')\n",
    "        \n",
    "    # save model\n",
    "    ckpt_savepath = Path(args.ckpt_savepath)\n",
    "    if not ckpt_savepath.parent.exists():\n",
    "        ckpt_savepath.parent.mkdir(parents=True)\n",
    "    ckpt_savepath = saver.save(sess, args.ckpt_savepath)\n",
    "    print(f\"Save model - {args.ckpt_savepath}\")\n",
    "    print(f\"Trining time - {str(datetime.now() - start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADaVJREFUeJzt3X+MXOV1xvHnib1e4jU0GILrGgcnhKA6NDjVxiSCVo4IKZAgEyWhWKrlSpRFLUhQRW2Rq6iWWqUUhSC3SSM5wY1BBGgCCCtx01CrrYVKHS/I2IBpTajT2DVewLQ2AfwDn/6x19EGdt5d5ted9fl+pNXO3HPv3KPrfXzvzDszryNCAPJ5R90NAKgH4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNT0bu5shvvjJA10c5dAKq/rZzochzyZdVsKv+1LJa2WNE3SNyPiltL6J2lAF/jiVnYJoGBzbJz0uk1f9tueJulrki6TtFDSMtsLm308AN3VynP+xZKejYjnIuKwpHslLW1PWwA6rZXwz5P00zH3d1fLfoHtIdvDtoeP6FALuwPQTh1/tT8i1kTEYEQM9qm/07sDMEmthH+PpPlj7p9ZLQMwBbQS/i2SzrH9XtszJF0taX172gLQaU0P9UXEUds3SPpHjQ71rY2Ip9rWGYCOammcPyI2SNrQpl4AdBFv7wWSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCplmbptb1L0kFJb0g6GhGD7WgKQOe1FP7KxyPixTY8DoAu4rIfSKrV8IekH9p+zPZQOxoC0B2tXvZfFBF7bJ8h6WHbz0TEprErVP8pDEnSSZrZ4u4AtEtLZ/6I2FP9HpH0oKTF46yzJiIGI2KwT/2t7A5AGzUdftsDtk8+flvSJyU92a7GAHRWK5f9cyQ9aPv443w7In7Qlq4AdFzT4Y+I5ySd38ZeAHQRQ31AUoQfSIrwA0kRfiApwg8kRfiBpNrxqb4UXrr2Yw1r71n+bHHbZ0bmFOuHD/UV6/PuKddn7n6lYe3Y1qeL2yIvzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/JP0x3/07Ya1zw68XN747BZ3vqRc3nX01Ya11S98vMWdT10/GjmrYW3gtl8qbjt942PtbqfncOYHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQcEV3b2SmeHRf44q7tr51+9rkLGtZe/FD5/9BTd5SP8cu/6mJ9xof+t1i/9bwHGtYueedrxW2//+qsYv1TMxt/V0CrXovDxfrmQwPF+pKTjjS97/d//7pi/QNDW5p+7Dptjo06EPvLf1AVzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNSEn+e3vVbSpyWNRMR51bLZku6TtEDSLklXRcQEH2qf2ga+u7lQa+2xT2ltc/3NLy9pWPuLCxeU9/2v5TkHbl3y/iY6mpzprx0r1ge27S3WT9t0f7H+azMaz3cwc1d5LoQMJnPm/5akS9+07GZJGyPiHEkbq/sAppAJwx8RmyTtf9PipZLWVbfXSbqyzX0B6LBmn/PPiYjj12TPSyrPRwWg57T8gl+Mfjig4ZvXbQ/ZHrY9fESHWt0dgDZpNvz7bM+VpOr3SKMVI2JNRAxGxGCf+pvcHYB2azb86yWtqG6vkPRQe9oB0C0Tht/2PZIelXSu7d22r5F0i6RLbO+U9InqPoApZMJx/ohY1qA0NT+YfwI6+vy+hrWB+xvXJOmNCR574LsvNdFRe+z7vY8V6x+cUf7z/fL+cxvWFvzdc8VtjxarJwbe4QckRfiBpAg/kBThB5Ii/EBShB9Iiim6UZvpZ80v1r+68qvFep+nFevfWf2JhrXT9j5a3DYDzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/KjNM384r1j/SH95pumnDpenH5/99Ktvu6dMOPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKM86OjDn3qIw1rj3/u9gm2Ls/w9Ps33lisv/PffjTB4+fGmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkppwnN/2WkmfljQSEedVy1ZJulbSC9VqKyNiQ6eaxNT135c1Pr/Mcnkcf9l/XVKsz/zBE8V6FKuYzJn/W5IuHWf57RGxqPoh+MAUM2H4I2KTpP1d6AVAF7XynP8G29tsr7V9ats6AtAVzYb/65LOlrRI0l5JtzVa0faQ7WHbw0d0qMndAWi3psIfEfsi4o2IOCbpG5IWF9ZdExGDETHYN8EHNQB0T1Phtz13zN3PSHqyPe0A6JbJDPXdI2mJpNNt75b0Z5KW2F6k0dGUXZKu62CPADpgwvBHxLJxFt/RgV4wBb3j5JOL9eW/8UjD2oFjrxe3HfnS+4r1/kNbinWU8Q4/ICnCDyRF+IGkCD+QFOEHkiL8QFJ8dTdasnPVB4v1753+tw1rS3d+trht/waG8jqJMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJMU4P4r+73c+Wqxv++2/LtZ/fPRIw9orf3Vmcdt+7S3W0RrO/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOP8yU2f9yvF+k1fvK9Y73f5T+jqJ5Y3rL37H/i8fp048wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUhOO89ueL+lOSXMkhaQ1EbHa9mxJ90laIGmXpKsi4uXOtYpmeHr5n/j87+0u1j8/66Vi/e6DZxTrc77Y+PxyrLglOm0yZ/6jkr4QEQslfVTS9bYXSrpZ0saIOEfSxuo+gCliwvBHxN6IeLy6fVDSDknzJC2VtK5abZ2kKzvVJID2e1vP+W0vkPRhSZslzYmI49+z9LxGnxYAmCImHX7bsyTdL+mmiDgwthYRodHXA8bbbsj2sO3hIzrUUrMA2mdS4bfdp9Hg3x0RD1SL99meW9XnShoZb9uIWBMRgxEx2Kf+dvQMoA0mDL9tS7pD0o6I+MqY0npJK6rbKyQ91P72AHTKZD7Se6Gk5ZK2295aLVsp6RZJf2/7Gkk/kXRVZ1pES84/t1j+8zPuaunhv/alzxfr73ri0ZYeH50zYfgj4hFJblC+uL3tAOgW3uEHJEX4gaQIP5AU4QeSIvxAUoQfSIqv7j4BTFv4gYa1oXtbe+/VwrXXF+sL7vr3lh4f9eHMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJMc5/AnjmD05tWLti5oGGtck4818Ol1eIcb+9DVMAZ34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIpx/ing9SsWF+sbr7itUJ3Z3mZwwuDMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJTTjOb3u+pDslzZEUktZExGrbqyRdK+mFatWVEbGhU41m9j8XTivW3zO9+bH8uw+eUaz3HSh/np9P809dk3mTz1FJX4iIx22fLOkx2w9Xtdsj4sudaw9Ap0wY/ojYK2lvdfug7R2S5nW6MQCd9bae89teIOnDkjZXi26wvc32WtvjfpeU7SHbw7aHj+hQS80CaJ9Jh9/2LEn3S7opIg5I+rqksyUt0uiVwbhvMI+INRExGBGDfepvQ8sA2mFS4bfdp9Hg3x0RD0hSROyLiDci4pikb0gqf/oEQE+ZMPy2LekOSTsi4itjls8ds9pnJD3Z/vYAdMpkXu2/UNJySdttb62WrZS0zPYijY727JJ0XUc6REv+8qWFxfqjv7WgWI+929vYDXrJZF7tf0SSxykxpg9MYbzDD0iK8ANJEX4gKcIPJEX4gaQIP5CUo4tTLJ/i2XGBL+7a/oBsNsdGHYj94w3NvwVnfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iqqvj/LZfkPSTMYtOl/Ri1xp4e3q1t17tS6K3ZrWzt7Mi4t2TWbGr4X/Lzu3hiBisrYGCXu2tV/uS6K1ZdfXGZT+QFOEHkqo7/Gtq3n9Jr/bWq31J9NasWnqr9Tk/gPrUfeYHUJNawm/7Utv/YftZ2zfX0UMjtnfZ3m57q+3hmntZa3vE9pNjls22/bDtndXvcadJq6m3Vbb3VMduq+3La+ptvu1/tv207ads31gtr/XYFfqq5bh1/bLf9jRJ/ynpEkm7JW2RtCwinu5qIw3Y3iVpMCJqHxO2/ZuSXpF0Z0ScVy27VdL+iLil+o/z1Ij4kx7pbZWkV+qeubmaUGbu2JmlJV0p6XdV47Er9HWVajhudZz5F0t6NiKei4jDku6VtLSGPnpeRGyStP9Ni5dKWlfdXqfRP56ua9BbT4iIvRHxeHX7oKTjM0vXeuwKfdWijvDPk/TTMfd3q7em/A5JP7T9mO2hupsZx5xq2nRJel7SnDqbGceEMzd305tmlu6ZY9fMjNftxgt+b3VRRPy6pMskXV9d3vakGH3O1kvDNZOaublbxplZ+ufqPHbNznjdbnWEf4+k+WPun1kt6wkRsaf6PSLpQfXe7MP7jk+SWv0eqbmfn+ulmZvHm1laPXDsemnG6zrCv0XSObbfa3uGpKslra+hj7ewPVC9ECPbA5I+qd6bfXi9pBXV7RWSHqqxl1/QKzM3N5pZWjUfu56b8Toiuv4j6XKNvuL/Y0l/WkcPDfp6n6Qnqp+n6u5N0j0avQw8otHXRq6RdJqkjZJ2SvonSbN7qLe7JG2XtE2jQZtbU28XafSSfpukrdXP5XUfu0JftRw33uEHJMULfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvp/uK0ZUt56JeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from outputs/01_mnist_CNN/mnist_layers.ckpt\n",
      "Model restored from outputs/01_mnist_CNN/mnist_layers.ckpt\n",
      "Testing accuracy: 0.9735999703407288\n",
      "Predict image label = [7]\n"
     ]
    }
   ],
   "source": [
    "# inference and test\n",
    "plt.imshow(mnist_data.test.images[0].reshape((28, 28)))\n",
    "plt.show()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # restore model\n",
    "    saver.restore(sess, args.ckpt_savepath)\n",
    "    print(f\"Model restored from {args.ckpt_savepath}\")\n",
    "    \n",
    "    # calc accuracy for MNIST test images\n",
    "    print(f\"Testing accuracy: {sess.run(accuracy, feed_dict={\\\n",
    "            x_train: mnist_data.test.images, y_train: mnist_data.test.labels})}\")\n",
    "    \n",
    "    # predict first test image\n",
    "    print(f\"Predict image label = {sess.run(tf.argmax(y_pred, 1), feed_dict={\\\n",
    "            x_train: mnist_data.test.images[0:1]})}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
